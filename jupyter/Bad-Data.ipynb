{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Managing Bad Data Entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bad or dirty data refers to information that can be erroneous, misleading, and without general formatting.  The impact of bad data can be distorted metrics and invalid reports.  To start fixing the data quality, you need to know what exactly is the cause of the bad data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine a sample dataset that contains total daily sales for a company during years 2010 and 2011 by product category and whether the total sales amount was for online purchases.  This data is stored as a CSV file on the Math@Work server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date         category total_sales is_online\n",
      "0    2/5/2010           Cereal       205.7     FALSE\n",
      "1   2/12/2010  Office Supplies      651.21      TRUE\n",
      "2  02/19/2010           Fruits        9.33     FALSE\n",
      "3  02/26/2010  Office Supplies      651.21     FALSE\n",
      "4    3/5/2010        Baby Food      255.28     FALSE\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "sales = pd.read_csv('https://mathatwork.org/DATA/bad-data.csv')\n",
    "print(sales.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check the quality of this dataset, we will need to explore the data in every data column.  Let's start with the *date* column.  This column appears to contain dates.  Let's verify this by checking the data type of this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n"
     ]
    }
   ],
   "source": [
    "print(sales.date.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code confirms that the data in the *date* column is of type string (or object).  It is a good idea to convert this column to type datetime which is more appropriate for the data it contains.  Import **datetime** from the *datetime* libray to use it for this conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "sales.date = pd.to_datetime(sales.date)\n",
    "print(sales.date.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After printing the data type of the converted column, we see that the data type for the *date* column is now *datetime*.  Since the data is supposed to be for years 2010 and 2011, filter out any data rows not equal to these years using Pandas **.dt.year** method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>category</th>\n",
       "      <th>total_sales</th>\n",
       "      <th>is_online</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>1945-09-09</td>\n",
       "      <td>Vegetables</td>\n",
       "      <td>154.06</td>\n",
       "      <td>TRUE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date    category total_sales is_online\n",
       "84 1945-09-09  Vegetables      154.06      TRUE"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales[(sales['date'].dt.year != 2010) & (sales['date'].dt.year != 2011)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The filter exposed that there is indeed a bad date in the dataset at data row 84.  You will need to gather more insights regarding this particular sale to determinine how to fix the date.  For this lesson, let's assume the year should be 2011."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sales.date.loc[84] = datetime.strptime('09-09-2011', '%m-%d-%Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas **datetime.strptime( )** is used to parse the new date string '09-09-2011' to appropriate *datetime* format before replacing the bad date in row 84.  Pandas **.loc[ ]** method allows us to pass in the row number of the row we want to select."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>category</th>\n",
       "      <th>total_sales</th>\n",
       "      <th>is_online</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [date, category, total_sales, is_online]\n",
       "Index: []"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales[(sales['date'].dt.year != 2010) & (sales['date'].dt.year != 2011)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying the same filter above exposes there are no more bad dates in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's move on to the *category* column. This column appears to contain text. Let's verify this by checking the data type of this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n"
     ]
    }
   ],
   "source": [
    "print(sales.category.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great.  The code confirms that the data in the *category* column is indeed of type string (or object). Intuitively, the *category* data column should not be a *\"free for all\"* data entry field.  Instead, it should contain a small set of standardized categories.  Let's explore the data in this column by using the Pandas **.unique( )** method to give us a listing of all the unique values in this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Baby Food' 'Beverages' 'Cereal' 'Clothes' 'Cosmetics' 'Fruits'\n",
      " 'Household' 'Households' 'Meat' 'Office Supplies' 'Personal Care' 'Snacks'\n",
      " 'Vegetables']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.sort(sales.category.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It may be better to sort the listing in order to see similarities in unique categories more clearly.  The Numpy library was imported so that its **.sort( )** method could be applied.  For more details regarding Numpy's **.sort( )** method review the Python for Data Science workshop.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see from the unique listing of categories that we have a *Household* and a *Households* category.  This is probably a typo.  You will need to gather more insights regarding this particular category to determinine which is should be. For this lesson, let's assume the category should be *Household*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sales.category.replace('Households', 'Household', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code, we applied Pandas **.replace( )** method to the category column in order to replace the category *Households* with *Household*.  We passed in *inplace=True* to make the change to the original *sales* DataFrame and not a copy of it.  A quick check of unique categories verifies the change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Baby Food' 'Beverages' 'Cereal' 'Clothes' 'Cosmetics' 'Fruits'\n",
      " 'Household' 'Meat' 'Office Supplies' 'Personal Care' 'Snacks' 'Vegetables']\n"
     ]
    }
   ],
   "source": [
    "print(np.sort(sales.category.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great. Let's move on to the *total_sales* column. This column appears to contain numerical data. Let's verify this by checking the data type of this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n"
     ]
    }
   ],
   "source": [
    "print(sales.total_sales.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code confirms that the data in the *total_sales* column is of type string (or object). It is a good idea to convert this column to type numeric which is more appropriate for the data it contains. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unable to parse string \"FALSE\" at position 50",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32mpandas/_libs/src/inference.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.maybe_convert_numeric (pandas/_libs/lib.c:55951)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unable to parse string \"FALSE\"",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-3d8194433a9e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msales\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_sales\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msales\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_sales\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/alicia/anaconda/envs/week1/lib/python3.6/site-packages/pandas/core/tools/numeric.py\u001b[0m in \u001b[0;36mto_numeric\u001b[0;34m(arg, errors, downcast)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0mcoerce_numeric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'raise'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             values = lib.maybe_convert_numeric(values, set(),\n\u001b[0;32m--> 126\u001b[0;31m                                                coerce_numeric=coerce_numeric)\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/src/inference.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.maybe_convert_numeric (pandas/_libs/lib.c:56433)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unable to parse string \"FALSE\" at position 50"
     ]
    }
   ],
   "source": [
    "sales.total_sales = pd.to_numeric(sales.total_sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oops!  The error message above let's us know that there is invalid data in this column at row 50.  Let's filter this row out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date           2011-01-14 00:00:00\n",
       "category                   Clothes\n",
       "total_sales                  FALSE\n",
       "is_online                   109.28\n",
       "Name: 50, dtype: object"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales.loc[50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon filtering we see that while *total_sales* is FALSE, *is_online* is 109.28.  This data was probably switched or entered in the wrong fields.  You will need to gather more insights regarding this particular row to determinine whether the 2 data fields were truly switched. For this lesson, let's assume *total_sales* should be 109.28 and *is_online* should be FALSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At row 50, replace the data in *total_sales* with 109.28 and in *is_online* with FALSE.  After making your replacement, be sure to filter this row again to check the changes you made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the invalid data fixed, we should now be able to convert the *total_sales* column to the appropriate numeric data type.  A quick check of this column's data type after conversion will confirm the change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n"
     ]
    }
   ],
   "source": [
    "sales.total_sales = pd.to_numeric(sales.total_sales)\n",
    "print(sales.total_sales.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great.  The *total_sales* column is now of datatype *float* with double precision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's move on to the *is_online* column. This column appears to contain text. Let's verify this by checking the data type of this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n"
     ]
    }
   ],
   "source": [
    "print(sales.is_online.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great. The code confirms that the data in the *is_online* column is indeed of type string (or object). Futhermore, the *is_online* column appears to contain only the values TRUE or FALSE. Let's explore the data in this column by using the Pandas .unique( ) method to give us a listing of all the unique values in this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['FALSE' 'TRUE' 'FLASE']\n"
     ]
    }
   ],
   "source": [
    "print(sales.is_online.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code confirms that the data contains a misspelling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1)** Filter to locate the misspelling in the *is_online* column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2)** Replace all occurrences of the misspelling with FALSE.  After making your replacement, be sure to filter this row again to check the changes you made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome.  All the columns have now been checked (and managed) for bad data.  We are now ready to check for duplicated rows.  Intuitively, in this dataset all rows should be unique.  That is, no 2 rows should contain the exact same data entries.  Use Pandas **.duplicated( )** to perform this check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    is_duplicate\n",
       "39          True"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicates = pd.DataFrame(sales.duplicated(), columns=['is_duplicate'])\n",
    "duplicates[duplicates.is_duplicate == True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to note that **.duplicated( )** returns True when a duplicate row is found.  In the above code, we created a DataFrame named *duplicates* by returning True in the column *is_duplicate* if the row is repeated and False in the column *is_duplicate* if the row is unique.  A quick filter on True exposes that row 39 is duplicated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apple Pandas **.drop( )** method to the *sales* DataFrame and pass in 39 to drop row 39 from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [is_duplicate]\n",
       "Index: []"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales.drop(39, inplace=True)\n",
    "\n",
    "duplicates = pd.DataFrame(sales.duplicated(), columns=['is_duplicate'])\n",
    "duplicates[duplicates.is_duplicate == True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recreating the *duplicates* table and then filtering it on True confirms that the duplicate row was indeed dropped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice.  Presumably at this point, your data has been properly managed for bad data entries."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
